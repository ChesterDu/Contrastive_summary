{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('contras_sum': conda)",
   "metadata": {
    "interpreter": {
     "hash": "8cb9d025c05246ef6003f562bd78c39f89a3e3de8b2c6293d42fd24001b7bf88"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "  def __init__(self):\n",
    "    self.summary_method = \"none\"\n",
    "    self.model_dir = \"fusing_finetune_ckpt.pkl\"\n",
    "    self.log_dir = \"fusing_finetune_log.pkl\"\n",
    "    self.use_pretrain = True\n",
    "    self.log_step = 200\n",
    "    self.toy = True\n",
    "    self.toy_size = 80000\n",
    "    self.batch_size = 16\n",
    "    self.num_neg = 4\n",
    "    self.max_len = 200\n",
    "    self.lr = 1e-5\n",
    "    self.steps = 50000\n",
    "    self.clip = 1.0\n",
    "    self.dist_func = \"cosin\"\n",
    "    self.local_rank = 0\n",
    "    self.gpu_ids = 0\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/newdisk/yangkai/contras_sum\")\n",
    "import torch\n",
    "import tqdm\n",
    "from finetune_data import read_all_sequences\n",
    "import os\n",
    "from transformers import RobertaTokenizer, RobertaConfig, RobertaForSequenceClassification\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 29%|██▊       | 65/227 [00:00<00:00, 606.29it/s]Read all sequences begin=====\n",
      "100%|██████████| 227/227 [00:00<00:00, 751.49it/s]\n"
     ]
    }
   ],
   "source": [
    "train_seqs, test_seqs= read_all_sequences(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=80000.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4c5216cda297407183c77fc10776b85c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "ipykernel_launcher:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9165.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fb80d99f4831489ba4631927eb09ebb3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "train_sum_seqs = [(x, summarizer.sum_text(x),y) for x,y in tqdm.tqdm_notebook(train_seqs)]\n",
    "test_sum_seqs = [(x, summarizer.sum_text(x),y) for x,y in tqdm.tqdm_notebook(test_seqs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "def make_fusing_dataset(args,seqs):\n",
    "    x_ids = []\n",
    "    x_sum_ids = []\n",
    "    seq_num = len(seqs)\n",
    "    labels = torch.LongTensor(seq_num)\n",
    "    for i, (x,x_sum,y) in enumerate(seqs):\n",
    "        x_ids.append(x)\n",
    "        x_sum_ids.append(x_sum)\n",
    "        labels[i] = y\n",
    "\n",
    "    x_ids = tokenizer(x_ids, padding = 'max_length', max_length = args.max_len, truncation = True, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    x_sum_ids = tokenizer(x_sum_ids, padding = 'max_length', max_length = 50, truncation = True, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    dataset = TensorDataset(x_ids, x_sum_ids, labels)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "train_dataset = make_fusing_dataset(args,train_sum_seqs)\n",
    "test_dataset = make_fusing_dataset(args,test_sum_seqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load(\"dataset/processed_finetune_fusing_dataset.pkl\")\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,batch_size = args.batch_size, shuffle=True, drop_last = True, num_workers = 3)\n",
    "test_loader = DataLoader(test_dataset, batch_size = args.batch_size, shuffle = False, drop_last = True, num_workers = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "config = RobertaConfig.from_pretrained(\"roberta-base\")\n",
    "config.num_labels = 2\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\",config=config)\n",
    "if args.use_pretrain:\n",
    "    pretained_weight = torch.load(\"checkpoint.pkl\", map_location='cpu')\n",
    "    for key in pretained_weight:\n",
    "        pretained_weight[key] = pretained_weight[key].cpu()\n",
    "    model_weight = model.state_dict()\n",
    "    for key in pretained_weight:\n",
    "        if \"pooler\" in key:\n",
    "            continue\n",
    "        new_key = key.replace(\"module.base_model\",\"roberta\")\n",
    "        model_weight[new_key] = deepcopy(pretained_weight[key])\n",
    "\n",
    "    model.load_state_dict(model_weight)\n",
    "sum_model = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device1 = torch.device(\"cuda:1\")\n",
    "device2 = torch.device(\"cuda:2\")\n",
    "model = model.to(device1)\n",
    "sum_model = sum_model.to(device2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opt import OpenAIAdam\n",
    "optimizer1 = OpenAIAdam(model.parameters(),\n",
    "                                  lr=args.lr,\n",
    "                                  schedule='warmup_linear',\n",
    "                                  warmup=0.002,\n",
    "                                  t_total=args.steps,\n",
    "                                  b1=0.9,\n",
    "                                  b2=0.999,\n",
    "                                  e=1e-08,\n",
    "                                  l2=0.01,\n",
    "                                  vector_l2=True,\n",
    "                                  max_grad_norm=args.clip)\n",
    "optimizer2 = OpenAIAdam(sum_model.parameters(),\n",
    "                                  lr=args.lr,\n",
    "                                  schedule='warmup_linear',\n",
    "                                  warmup=0.002,\n",
    "                                  t_total=args.steps,\n",
    "                                  b1=0.9,\n",
    "                                  b2=0.999,\n",
    "                                  e=1e-08,\n",
    "                                  l2=0.01,\n",
    "                                  vector_l2=True,\n",
    "                                  max_grad_norm=args.clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critirion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "step = 0\n",
    "bar = tqdm.tqdm(total=args.steps)\n",
    "bar.update(0)\n",
    "loss_list = []\n",
    "best_acc = 0\n",
    "logs = []\n",
    "\n",
    "while(step < args.steps):\n",
    "    for batch in train_loader:\n",
    "        optimizer1.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "        x_ids, x_sum_ids, labels = batch[0].to(device1), batch[1].to(device2), batch[2].to(device1)\n",
    "        logits1 = model(x_ids,labels = labels)[1]\n",
    "        logits2 = sum_model(x_sum_ids, labels = labels.to(device2))[1]\n",
    "        logits = logits1.to(device2) + logits2\n",
    "        # print(loss.item())\n",
    "\n",
    "        loss =critirion(logits,labels.to(device2))\n",
    "        \n",
    "        loss.backward()\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        optimizer1.step()\n",
    "        optimizer2.step()\n",
    "        step += 1\n",
    "        if (step % 10 == 0):\n",
    "            bar.update(10)\n",
    "        \n",
    "        if (step % args.log_step == 0):\n",
    "            \n",
    "            print(\"step: \",step)\n",
    "            print(\"loss: \",sum(loss_list)/step)\n",
    "            log = {\"step\":step, \"loss\":sum(loss_list)/step}\n",
    "            log = evaluate_model(model,test_loader,log)\n",
    "            logs.append(log)\n",
    "            torch.save(logs, args.log_dir)\n",
    "            \n",
    "            if (log[\"acc\"] > best_acc):\n",
    "                best_acc = log[\"acc\"]\n",
    "                torch.save(model.state_dict(),args.model_dir)\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, log):\n",
    "    print(\"Evaluation Start======\")\n",
    "    model.eval()\n",
    "    TP, TN, FN, FP = 0, 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            x_ids, x_sum_ids, labels = batch[0].to(device1), batch[1].to(device2), batch[2].to(device1)\n",
    "            logits1 = model(x_ids,labels = labels)[1]\n",
    "            logits2 = sum_model(x_sum_ids, labels = labels.to(device2))[1]\n",
    "            logits = logits1.to(device2) + logits2\n",
    "            # print(logits)\n",
    "\n",
    "            prediction = torch.argmax(logits, dim = 1)\n",
    "            TP += ((prediction == 1) & (labels.to(device2) == 1)).sum().item()\n",
    "            # TN    predict 和 label 同时为0\n",
    "            TN += ((prediction == 0) & (labels.to(device2) == 0)).sum().item()\n",
    "            # FN    predict 0 label 1\n",
    "            FN += ((prediction == 0) & (labels.to(device2) == 1)).sum().item()\n",
    "            # FP    predict 1 label 0\n",
    "            FP += ((prediction == 1) & (labels.to(device2) == 0)).sum().item()\n",
    "\n",
    "    p = TP / (TP + FP)\n",
    "    r = TP / (TP + FN)\n",
    "    F1 = 2 * r * p / (r + p)\n",
    "    acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "    print(\"recall: \",r)\n",
    "    print(\"precision: \",p)\n",
    "    print(\"F1: \",F1)\n",
    "    print(\"Acc: \",acc)\n",
    "\n",
    "    log[\"recall\"] = r\n",
    "    log[\"precision\"] = p\n",
    "    log[\"F1\"] = F1\n",
    "    log[\"acc\"] = acc\n",
    "\n",
    "    return log"
   ]
  }
 ]
}